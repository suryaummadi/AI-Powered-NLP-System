{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:26:21.993003Z",
     "iopub.status.busy": "2025-08-11T17:26:21.992720Z",
     "iopub.status.idle": "2025-08-11T17:26:21.996818Z",
     "shell.execute_reply": "2025-08-11T17:26:21.996050Z",
     "shell.execute_reply.started": "2025-08-11T17:26:21.992983Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:11:18.234748Z",
     "iopub.status.busy": "2025-08-11T16:11:18.234449Z",
     "iopub.status.idle": "2025-08-11T16:11:26.456749Z",
     "shell.execute_reply": "2025-08-11T16:11:26.456180Z",
     "shell.execute_reply.started": "2025-08-11T16:11:18.234725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e722ed40758b4b8fa2f98851272e4d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/854 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8a74bdfedd41f0a624631750722e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/8.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415079c9bfb47f486adb56698e999c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"theArijitDas/Fake-Reviews-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:13:09.354723Z",
     "iopub.status.busy": "2025-08-11T16:13:09.354356Z",
     "iopub.status.idle": "2025-08-11T16:13:09.359824Z",
     "shell.execute_reply": "2025-08-11T16:13:09.359139Z",
     "shell.execute_reply.started": "2025-08-11T16:13:09.354700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['category', 'rating', 'text', 'label'],\n",
       "        num_rows: 40526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:17:35.294880Z",
     "iopub.status.busy": "2025-08-11T16:17:35.294319Z",
     "iopub.status.idle": "2025-08-11T16:17:35.298398Z",
     "shell.execute_reply": "2025-08-11T16:17:35.297594Z",
     "shell.execute_reply.started": "2025-08-11T16:17:35.294852Z"
    }
   },
   "outputs": [],
   "source": [
    "df = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:26:03.298802Z",
     "iopub.status.busy": "2025-08-11T16:26:03.298530Z",
     "iopub.status.idle": "2025-08-11T16:26:03.323460Z",
     "shell.execute_reply": "2025-08-11T16:26:03.322742Z",
     "shell.execute_reply.started": "2025-08-11T16:26:03.298782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['category', 'rating', 'text', 'label'],\n",
      "        num_rows: 28367\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['category', 'rating', 'text', 'label'],\n",
      "        num_rows: 4053\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['category', 'rating', 'text', 'label'],\n",
      "        num_rows: 8106\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Step 1: Split into 80% train and 20% test\n",
    "train_test_split = df['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Step 2: Split the 80% train into 70% train and 10% validation\n",
    "train_valid_split = train_test_split['train'].train_test_split(test_size=0.125, seed=42) \n",
    "# 0.125 because 0.125 * 0.8 = 0.1 of original dataset\n",
    "\n",
    "# Step 3: Combine into DatasetDict\n",
    "dataset_splits = DatasetDict({\n",
    "    'train': train_valid_split['train'],         # 70%\n",
    "    'validation': train_valid_split['test'],     # 10%\n",
    "    'test': train_test_split['test']             # 20%\n",
    "})\n",
    "\n",
    "print(dataset_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:26:10.870771Z",
     "iopub.status.busy": "2025-08-11T16:26:10.870486Z",
     "iopub.status.idle": "2025-08-11T16:26:10.879518Z",
     "shell.execute_reply": "2025-08-11T16:26:10.878827Z",
     "shell.execute_reply.started": "2025-08-11T16:26:10.870750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 28367\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 4053\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 8106\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'category' and 'rating' columns from all splits\n",
    "dataset_clean = dataset_splits.remove_columns(['category', 'rating'])\n",
    "print(dataset_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FacebookAI/roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:28:35.744051Z",
     "iopub.status.busy": "2025-08-11T16:28:35.743470Z",
     "iopub.status.idle": "2025-08-11T16:28:37.957126Z",
     "shell.execute_reply": "2025-08-11T16:28:37.956531Z",
     "shell.execute_reply.started": "2025-08-11T16:28:35.744026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e17e457d284ecd8534f458a2e73ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857b4a5932794ba5aa3e57ff79d79816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184edd823ec743ca8047da1a9da9c37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd0f7f6cd7a4fa1a89425a7fe9201c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca43ec688db4f27af1d324e5075c9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:29:34.078122Z",
     "iopub.status.busy": "2025-08-11T16:29:34.077481Z",
     "iopub.status.idle": "2025-08-11T16:29:40.808493Z",
     "shell.execute_reply": "2025-08-11T16:29:40.807532Z",
     "shell.execute_reply.started": "2025-08-11T16:29:34.078097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eedcaf1ef44f75a4c482cc9484c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b8883cba60441a8dee8ec165dc0470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec991d328de42b79b6f36bd1819a690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a tokenization function\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the text column, truncating/padding as needed\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenization to each split using map()\n",
    "dataset_dict = dataset_clean.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:29:48.153427Z",
     "iopub.status.busy": "2025-08-11T16:29:48.152889Z",
     "iopub.status.idle": "2025-08-11T16:29:48.158694Z",
     "shell.execute_reply": "2025-08-11T16:29:48.157942Z",
     "shell.execute_reply.started": "2025-08-11T16:29:48.153402Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the format to pytorch tensors if you want to use Trainer directly\n",
    "dataset_dict.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:29:50.278488Z",
     "iopub.status.busy": "2025-08-11T16:29:50.278190Z",
     "iopub.status.idle": "2025-08-11T16:29:50.283549Z",
     "shell.execute_reply": "2025-08-11T16:29:50.282743Z",
     "shell.execute_reply.started": "2025-08-11T16:29:50.278465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 28367\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4053\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 8106\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:30:04.480721Z",
     "iopub.status.busy": "2025-08-11T16:30:04.480442Z",
     "iopub.status.idle": "2025-08-11T16:30:05.802741Z",
     "shell.execute_reply": "2025-08-11T16:30:05.802065Z",
     "shell.execute_reply.started": "2025-08-11T16:30:04.480701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'label']\n"
     ]
    }
   ],
   "source": [
    "def reorder_columns(ds, order):\n",
    "    data = {k: ds[k] for k in order}\n",
    "    return ds.from_dict(data)\n",
    "\n",
    "new_order = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "dataset_dict[\"train\"] = reorder_columns(dataset_dict[\"train\"], new_order)\n",
    "dataset_dict[\"validation\"] = reorder_columns(dataset_dict[\"validation\"], new_order)\n",
    "dataset_dict[\"test\"] = reorder_columns(dataset_dict[\"test\"], new_order)\n",
    "\n",
    "print(dataset_dict[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:30:08.247426Z",
     "iopub.status.busy": "2025-08-11T16:30:08.246735Z",
     "iopub.status.idle": "2025-08-11T16:30:08.251667Z",
     "shell.execute_reply": "2025-08-11T16:30:08.251095Z",
     "shell.execute_reply.started": "2025-08-11T16:30:08.247402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 28367\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 4053\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 8106\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:30:12.382583Z",
     "iopub.status.busy": "2025-08-11T16:30:12.382341Z",
     "iopub.status.idle": "2025-08-11T16:30:24.814411Z",
     "shell.execute_reply": "2025-08-11T16:30:24.813825Z",
     "shell.execute_reply.started": "2025-08-11T16:30:12.382566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 16:30:13.808867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754929813.995040      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754929814.052687      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:31:53.208507Z",
     "iopub.status.busy": "2025-08-11T16:31:53.207862Z",
     "iopub.status.idle": "2025-08-11T16:31:53.501310Z",
     "shell.execute_reply": "2025-08-11T16:31:53.500598Z",
     "shell.execute_reply.started": "2025-08-11T16:31:53.208473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'FacebookAI/roberta-base',\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:31:59.340591Z",
     "iopub.status.busy": "2025-08-11T16:31:59.340118Z",
     "iopub.status.idle": "2025-08-11T16:32:00.578439Z",
     "shell.execute_reply": "2025-08-11T16:32:00.577613Z",
     "shell.execute_reply.started": "2025-08-11T16:31:59.340562Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"/kaggle/working/\")  #chaning working directory as per need\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/\",\n",
    "    report_to=\"none\",  \n",
    "    logging_dir=\"/kaggle/working/logs\",       \n",
    "    save_strategy=\"epoch\",               \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:32:04.465912Z",
     "iopub.status.busy": "2025-08-11T16:32:04.465632Z",
     "iopub.status.idle": "2025-08-11T16:32:05.419125Z",
     "shell.execute_reply": "2025-08-11T16:32:05.418343Z",
     "shell.execute_reply.started": "2025-08-11T16:32:04.465892Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:32:07.693689Z",
     "iopub.status.busy": "2025-08-11T16:32:07.693035Z",
     "iopub.status.idle": "2025-08-11T16:50:53.617283Z",
     "shell.execute_reply": "2025-08-11T16:50:53.616676Z",
     "shell.execute_reply.started": "2025-08-11T16:32:07.693657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 18:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.08828039549418602, metrics={'train_runtime': 1125.4734, 'train_samples_per_second': 75.614, 'train_steps_per_second': 4.726, 'total_flos': 5597753480547840.0, 'train_loss': 0.08828039549418602, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:51:18.211829Z",
     "iopub.status.busy": "2025-08-11T16:51:18.211569Z",
     "iopub.status.idle": "2025-08-11T16:51:32.570304Z",
     "shell.execute_reply": "2025-08-11T16:51:32.569730Z",
     "shell.execute_reply.started": "2025-08-11T16:51:18.211810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4053, 2) (4053,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset_dict[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
    "\n",
    "#predictions = trainer.predict(dataset_dict[\"test\"])\n",
    "#print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:51:37.325393Z",
     "iopub.status.busy": "2025-08-11T16:51:37.325083Z",
     "iopub.status.idle": "2025-08-11T16:51:37.329544Z",
     "shell.execute_reply": "2025-08-11T16:51:37.328689Z",
     "shell.execute_reply.started": "2025-08-11T16:51:37.325370Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:51:39.437098Z",
     "iopub.status.busy": "2025-08-11T16:51:39.436445Z",
     "iopub.status.idle": "2025-08-11T16:51:44.844031Z",
     "shell.execute_reply": "2025-08-11T16:51:44.843295Z",
     "shell.execute_reply.started": "2025-08-11T16:51:39.437076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:51:49.526926Z",
     "iopub.status.busy": "2025-08-11T16:51:49.526609Z",
     "iopub.status.idle": "2025-08-11T16:51:53.545647Z",
     "shell.execute_reply": "2025-08-11T16:51:53.545057Z",
     "shell.execute_reply.started": "2025-08-11T16:51:49.526897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc56d09abdd1432a8035a821e453c898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a967f2775f994d23a51861b6c7b86211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {'accuracy': 0.9726128793486306}\n",
      "F1 Score: {'f1': 0.9726027737747962}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load all required metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "#precision = evaluate.load(\"precision\")\n",
    "#recall = evaluate.load(\"recall\")\n",
    "\n",
    "# Compute predictions and labels\n",
    "acc_score = accuracy.compute(predictions=preds, references=labels)\n",
    "f1_score = f1.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "#precision_score = precision.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "#recall_score = recall.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", acc_score)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "#print(\"Precision:\", precision_score)\n",
    "#print(\"Recall:\", recall_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:52:45.639471Z",
     "iopub.status.busy": "2025-08-11T16:52:45.638783Z",
     "iopub.status.idle": "2025-08-11T16:52:46.641794Z",
     "shell.execute_reply": "2025-08-11T16:52:46.641170Z",
     "shell.execute_reply.started": "2025-08-11T16:52:45.639441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/quality_check_tokenizer/tokenizer_config.json',\n",
       " '/kaggle/working/quality_check_tokenizer/special_tokens_map.json',\n",
       " '/kaggle/working/quality_check_tokenizer/vocab.json',\n",
       " '/kaggle/working/quality_check_tokenizer/merges.txt',\n",
       " '/kaggle/working/quality_check_tokenizer/added_tokens.json',\n",
       " '/kaggle/working/quality_check_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model\n",
    "model.save_pretrained(\"/kaggle/working/quality_check_model\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/quality_check_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:52:50.237603Z",
     "iopub.status.busy": "2025-08-11T16:52:50.237358Z",
     "iopub.status.idle": "2025-08-11T16:52:50.256678Z",
     "shell.execute_reply": "2025-08-11T16:52:50.255893Z",
     "shell.execute_reply.started": "2025-08-11T16:52:50.237586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d011b52c9da741d2a5afe8c19f911133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:58:15.644422Z",
     "iopub.status.busy": "2025-08-11T16:58:15.644112Z",
     "iopub.status.idle": "2025-08-11T16:58:40.194519Z",
     "shell.execute_reply": "2025-08-11T16:58:40.193770Z",
     "shell.execute_reply.started": "2025-08-11T16:58:15.644401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997124b64589460a91a8a73b131cc125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9639ddfbd70d4069bae05905bb064898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/suryaummadi/review-roberta-quality-scoring-analytics/commit/33d6e893a4d70f5c8a1ba868d2c3f15bea5759a4', commit_message='Upload tokenizer', commit_description='', oid='33d6e893a4d70f5c8a1ba868d2c3f15bea5759a4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/suryaummadi/review-roberta-quality-scoring-analytics', endpoint='https://huggingface.co', repo_type='model', repo_id='suryaummadi/review-roberta-quality-scoring-analytics'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"suryaummadi/review-roberta-quality-scoring-analytics\")\n",
    "tokenizer.push_to_hub(\"suryaummadi/review-roberta-quality-scoring-analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from hugging face and working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:18:37.285889Z",
     "iopub.status.busy": "2025-08-11T17:18:37.285618Z",
     "iopub.status.idle": "2025-08-11T17:18:38.103033Z",
     "shell.execute_reply": "2025-08-11T17:18:38.102296Z",
     "shell.execute_reply.started": "2025-08-11T17:18:37.285868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake (computer-generated) review.\n",
      "Prediction: Original (authentic) review.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your fine-tuned fake vs original review classification model\n",
    "pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"suryaummadi/review-roberta-quality-scoring-analytics\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def classify_review(text):\n",
    "    outputs = pipe(text)\n",
    "    scores = outputs[0]  \n",
    "    \n",
    "    # Find label with highest score\n",
    "    top = max(scores, key=lambda x: x['score'])\n",
    "    label = top['label']  # 'LABEL_0' or 'LABEL_1'\n",
    "    score = top['score'] * 100\n",
    "\n",
    "    if label == 'LABEL_0':\n",
    "        result = \"Original (authentic) review\"\n",
    "    else:\n",
    "        result = \"Fake (computer-generated) review\"\n",
    "\n",
    "    #return f\"Prediction: {result} with confidence {score:.1f}%.\"\n",
    "    return f\"Prediction: {result}.\"\n",
    "\n",
    "# Example usage\n",
    "review = \"I recently ordered a new pair of headphones for my son's new computer, and I was pretty nervous about them.  The headphones fit him fine, but he didn't like the way they felt.  After a couple of days, they started to feel very uncomfortable.  The sound quality is a bit muddy, but the bass is good and the mids are good.  I'd rather have my son use them for listening to music on his computer, but that's not what I wanted for his new computer.\\n\\nThe sound quality is okay, but it isn't bad either.  I've found that it is\"\n",
    "print(classify_review(review))\n",
    "\n",
    "review2 = \"This is the best product ever! Buy it now!!!\"\n",
    "print(classify_review(review2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:22:43.898457Z",
     "iopub.status.busy": "2025-08-11T17:22:43.897848Z",
     "iopub.status.idle": "2025-08-11T17:22:43.901402Z",
     "shell.execute_reply": "2025-08-11T17:22:43.900686Z",
     "shell.execute_reply.started": "2025-08-11T17:22:43.898433Z"
    }
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
